---
title: AI Values, Resistance, and Situated Knowledge

call_to_action:
background_image_path:
large_header: false
show_in_navigation: false
navigation_order: 2
---

<div class="editable">
</div>

<p align="justify" style="font-family:'Arial';font-size:20px;">
<b>Amir H. Payberah - 2025-06-12</b>
</p>
<p align="justify" style="font-family:'Arial';font-size:20px;">
Who defines what counts as knowledge in AI? Whose values shape the systems we build? And how do people push back when those systems misrepresent or marginalize them?
</p>
<p align="justify" style="font-family:'Arial';font-size:20px;">
These questions are explored in three papers we read for our next journal club. Each takes a different yet connected approach to challenging dominant narratives of AI capability and the supposed universality of values. Instead, they offer a more grounded, situated, and human-centered perspective.
</p>
<p align="justify" style="font-family:'Arial';font-size:20px;">
The first paper, "Provocations from the Humanities for Generative AI Research" [1], by Lauren Klein and colleagues, critiques the core assumptions behind generative AI. They present eight provocations that question how AI systems handle language, culture, and meaning. The authors argue that AI models often reduce language to surface-level patterns while ignoring the social and historical contexts. They push back against the idea that scaling up or open-sourcing data can resolve deeper structural problems, especially when systems are built around the myth of a "universal" user.
</p>
<p align="justify" style="font-family:'Arial';font-size:20px;">
The second paper, "Basic Values in Artificial Intelligence: Comparative Factor Analysis in Estonia, Germany, and Sweden" [2], by Anu Masso, Anne Kaun, and Colin van Noordt, explores how people in Estonia, Germany, and Sweden understand and prioritize values in relation to AI. Based on survey data from 4500 respondents, the authors identify four core value dimensions: personal protection, social responsibility, diversity & sustainability, and efficiency. Some values are widely shared, while others vary across national and cultural lines. This research underscores the importance of rejecting one-size-fits-all ethical frameworks and instead developing ones that are sensitive to context and shaped by the public, not just by policy documents.
</p>
<p align="justify" style="font-family:'Arial';font-size:20px;">
The third paper, "Algorithmic Resistance: Media Practices and the Politics of Repair" [3], by Julia Velkova and Anne Kaun, turns to users and their capacity to resist algorithmic bias. Focusing on the "World White Web" campaign by Johanna Burai, which was an effort to diversify racially biased Google Image results, the authors introduce the idea of repair politics, a form of resistance where users tactically and creatively engage with existing systems to subvert, modify, and reconfigure algorithmic outputs. Rather than rejecting technology outright, these actions challenge dominant representations from within, showing that user agency does not disappear in the face of automation.
</p>
<p align="justify" style="font-family:'Arial';font-size:20px;">
Together, these papers show that AI is never neutral, and if we want technology to truly serve society, we must take seriously questions of power, difference, and situated context.</p>
</p>
<p align="justify" style="font-family:'Arial';font-size:20px;">
[1] Provocations from the Humanities for Generative AI Research, L. Klein et al., arXiv preprint arXiv:2502.19190, 2025<br>
[2] Basic Values in Artificial Intelligence: Comparative Factor Analysis in Estonia, Germany, and Sweden, A. Masso et al., AI & Society 39.6: 2775-2790, 2024<br>
[3] Algorithmic Resistance: Media Practices and the Politics of Repair, J. Velkova and A. Kaun, Information, Communication & Society 24.4: 523-540, 2021
</p>
<p align="justify">
</p>
